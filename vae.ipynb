{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzSB9osctEb2pqg+G2QIul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit1217/VAE/blob/main/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1-795nioIUdy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "  return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "MojTgtmbsZoe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((128,),(128,))])\n",
        "\n",
        "# Load MNIST dataset\n",
        "trainset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "testset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Data loaders\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=128, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=128,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbidGxdDM2CM",
        "outputId": "ab6b90bd-f1a3-47b4-b9b4-1256c164307c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 88999966.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 73638719.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32025280.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21429166.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,kernel,latent_dim):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.in_channels=in_channels\n",
        "    self.out_channels=out_channels\n",
        "    self.latent_dim=latent_dim\n",
        "    self.conv1=nn.Conv2d(in_channels,out_channels,kernel+2)\n",
        "    self.conv2=nn.Conv2d(out_channels,out_channels,kernel)\n",
        "    self.conv3=nn.Conv2d(out_channels,out_channels,kernel)\n",
        "    self.conv4=nn.Conv2d(out_channels,out_channels,kernel)\n",
        "    self.conv5=nn.Conv2d(out_channels,2,kernel)\n",
        "    self.conv6=nn.Conv2d(out_channels,2,kernel)\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.conv3(x)\n",
        "    x=self.conv4(x)\n",
        "    x=self.conv5(x)\n",
        "    mean,log_variance=x[:,0],x[:,1]\n",
        "    epsilon=torch.randn(self.latent_dim,self.latent_dim).to(get_device())\n",
        "    z=mean+epsilon*(1+log_variance)\n",
        "    return mean,log_variance,z\n",
        "\n",
        "'''enc=Encoder(1,64,5,6)\n",
        "x=enc(torch.ones(6,1,28,28))\n",
        "x[0].shape,x[2].shape'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0brnBAIoNPY6",
        "outputId": "580b9730-a671-4234-c6ee-980a13f64407"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'enc=Encoder(1,64,5,6)\\nx=enc(torch.ones(6,1,28,28))\\nx[0].shape,x[2].shape'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,kernel,input_dim):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.in_channels=in_channels\n",
        "    self.out_channels=out_channels\n",
        "    self.input_dim=input_dim\n",
        "    self.conv1=nn.ConvTranspose2d(in_channels,out_channels,kernel )\n",
        "    self.conv2=nn.ConvTranspose2d(out_channels,out_channels,kernel)\n",
        "    self.conv3=nn.ConvTranspose2d(out_channels,out_channels,kernel)\n",
        "    self.conv4=nn.ConvTranspose2d(out_channels,out_channels,kernel)\n",
        "    self.conv5=nn.ConvTranspose2d(out_channels,2,kernel+2)\n",
        "    self.conv6=nn.ConvTranspose2d(out_channels,out_channels,kernel)\n",
        "    self.bn1=\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.conv1(x))\n",
        "    x=F.relu(self.conv2(x))\n",
        "    x=F.relu(self.conv3(x))\n",
        "    x=F.relu(self.conv4(x))\n",
        "    x=F.relu(self.conv5(x))\n",
        "    mean,variance=x[:,0],x[:,1]\n",
        "    epsilon=torch.randn(self.input_dim,self.input_dim).to(get_device())\n",
        "    return mean+epsilon*variance\n",
        "\n",
        "'''enc=Decoder(1,64,5,28)\n",
        "x=enc(torch.ones(2,1,6,6))\n",
        "x.shape,x'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7TlJd5_xNtku",
        "outputId": "bc3f286d-b6ea-4ada-87cf-ca87b62bab3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'enc=Decoder(1,64,5,28)\\nx=enc(torch.ones(2,1,6,6))\\nx.shape,x'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self,input_dim,latent_dim,in_channels,out_channels,kernel):\n",
        "    super(VAE,self).__init__()\n",
        "    self.input_dim=input_dim\n",
        "    self.latent_dim=latent_dim\n",
        "    self.encoder=Encoder(in_channels,out_channels,kernel,latent_dim)\n",
        "    self.decoder=Decoder(in_channels,out_channels,kernel,input_dim)\n",
        "    self.e=1e-8\n",
        "\n",
        "  def forward(self,x):\n",
        "    z,mean,log_variance=self.encoder(x)\n",
        "    b,w,h=z.shape\n",
        "    z=z.view(b,1,w,h)\n",
        "    x=x.view(b,self.input_dim,self.input_dim)\n",
        "    x_re=self.decoder(z)\n",
        "    return x_re,x,mean,log_variance\n",
        "\n",
        "'''vae=VAE(28,6,1,64,5)\n",
        "x=vae(torch.randn(6,1,28,28))\n",
        "x[0].shape,x[1].shape,x[2].shape,x[3].shape,x'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AaofEvO7TO1y",
        "outputId": "27ab4541-68d4-4d92-cda8-0e9514c38d6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vae=VAE(28,6,1,64,5)\\nx=vae(torch.randn(6,1,28,28))\\nx[0].shape,x[1].shape,x[2].shape,x[3].shape,x'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Loss(x_re,x_or,mean,log_variance):\n",
        "  re_loss=F.binary_cross_entropy_with_logits(x_re,x_or)\n",
        "  b,c,c=mean.shape\n",
        "  log_variance=log_variance.view(b,c*c)\n",
        "  mean=mean.view(b,c*c)\n",
        "  kl=torch.sum(0.5*(1+2*log_variance-torch.pow(log_variance,2)-torch.pow(mean,2)),dim=1)\n",
        "  kl=torch.mean(kl)\n",
        "  return (re_loss+kl)\n",
        "'''Loss(x[0],x[1],x[2],x[3])'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GEdJOX_GiBVl",
        "outputId": "d2184c0a-503d-468b-aa4f-87d62fef1b69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Loss(x[0],x[1],x[2],x[3])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOXDu_EzmOMv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=VAE(28,6,1,64,5)\n",
        "model=model.to(get_device())\n",
        "epochs=50\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.0001)\n",
        "for epoch in range(epochs):\n",
        "  total_loss=0\n",
        "  count=0\n",
        "  for x,_ in trainloader:\n",
        "    x=x.to(get_device())\n",
        "    x_re,x,mean,log_variance=model(x)\n",
        "    loss=Loss(x_re,x,mean,log_variance)\n",
        "\n",
        "    total_loss+=loss.item()\n",
        "    count+=1\n",
        "    print(total_loss)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    #for name, param in model.decoder.named_parameters():\n",
        "    #  if param.grad is not None:\n",
        "    #    pass\n",
        "    #      #print(f'a')\n",
        "      #print(x_re,x,mean,log_variance,loss)\n",
        "\n",
        "\n",
        "  print(f'total_loss{total_loss},mse_loss{total_loss/count},epoch{epoch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "82zkGTYZpjqy",
        "outputId": "f5143db2-11d6-420e-fe16-e0819f31c311"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-10.40577220916748\n",
            "-17.277010440826416\n",
            "-55.018274784088135\n",
            "-110.26222467422485\n",
            "-233.97408533096313\n",
            "-514.3406624794006\n",
            "-845.3238167762756\n",
            "-1925.7286019325256\n",
            "-3083.226770877838\n",
            "-5467.070276737213\n",
            "-10309.811487674713\n",
            "-16771.887659549713\n",
            "-27611.445276737213\n",
            "-46957.66012048721\n",
            "-75880.99019861221\n",
            "-129116.24801111221\n",
            "-200827.9433236122\n",
            "-303734.6151986122\n",
            "-483904.6776986122\n",
            "-726155.2401986122\n",
            "-1068454.2089486122\n",
            "-1413259.7089486122\n",
            "-1979216.7714486122\n",
            "-2980795.271448612\n",
            "-4331390.521448612\n",
            "-5976596.646448612\n",
            "-8372406.896448612\n",
            "-10894162.146448612\n",
            "-14905905.646448612\n",
            "-18974835.396448612\n",
            "-23891855.396448612\n",
            "-33579386.39644861\n",
            "-44404729.39644861\n",
            "-58207576.39644861\n",
            "-74615047.39644861\n",
            "-93934359.39644861\n",
            "-125706543.39644861\n",
            "-171649511.3964486\n",
            "-223240219.3964486\n",
            "-269496395.3964486\n",
            "-347136139.3964486\n",
            "-429554635.3964486\n",
            "-517058091.3964486\n",
            "-616366155.3964486\n",
            "-750298675.3964486\n",
            "-918018835.3964486\n",
            "-1110245843.3964486\n",
            "-1273551651.3964486\n",
            "-1636481763.3964486\n",
            "-2051661667.3964486\n",
            "-2403940835.3964486\n",
            "-2875924227.3964486\n",
            "-3330101571.3964486\n",
            "-3736873635.3964486\n",
            "-4405174563.396448\n",
            "-5290133987.396448\n",
            "-6058389219.396448\n",
            "-7284931683.396448\n",
            "-8953776483.396448\n",
            "-10455065955.396448\n",
            "-12162421475.396448\n",
            "-15060727011.396448\n",
            "-17181692131.396446\n",
            "-19877570787.396446\n",
            "-23235786467.396446\n",
            "-26363134179.396446\n",
            "-30244415715.396446\n",
            "-33898092003.396446\n",
            "-38825465315.39645\n",
            "-45276704227.39645\n",
            "-50961161699.39645\n",
            "-61805500899.39645\n",
            "-71904459235.39645\n",
            "-82324424163.39645\n",
            "-95779262947.39645\n",
            "-107956080099.39645\n",
            "-126380051939.39645\n",
            "-139672507875.39645\n",
            "-157621315043.39645\n",
            "-176334886371.39645\n",
            "-200154586595.39645\n",
            "-226369113571.39645\n",
            "-248741754339.39645\n",
            "-278054725091.3965\n",
            "-313924183523.3965\n",
            "-356402357731.3965\n",
            "-402588927459.3965\n",
            "-448700958179.3965\n",
            "-494715442659.3965\n",
            "-545964332515.3965\n",
            "-598663738851.3965\n",
            "-665610237411.3965\n",
            "-744215672291.3965\n",
            "-818091488739.3965\n",
            "-923677275619.3965\n",
            "-1052505880035.3965\n",
            "-1171898676707.3965\n",
            "-1289572816355.3965\n",
            "-1460907611619.3965\n",
            "-1648645314019.3965\n",
            "-1776530724323.3965\n",
            "-1935280018915.3965\n",
            "-2196709840355.3965\n",
            "-2344996214243.3965\n",
            "-2572209001955.3965\n",
            "-2781276509667.3965\n",
            "-3070576629219.3965\n",
            "-3435297052131.3965\n",
            "-3702273414627.3965\n",
            "-4088890594787.3965\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-32ba05a3d03d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtotal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx_re\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_variance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(x)\n",
        "z=torch.randn(6,1,6,6)\n",
        "z=z.to('cuda:0')\n",
        "x=model.decoder(z)\n",
        "print(x[0].shape)\n",
        "x=x[0]\n",
        "x=x.view(28,28)\n",
        "#x=data[0].view(28,28)\n",
        "x=x.to('cpu')\n",
        "image_np = x.detach().numpy()\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(image_np, cmap='gray')  # 'gray' colormap is used for grayscale images\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8lXkmhqs3UGY",
        "outputId": "d9944e03-42d2-40da-af60-da4fa053091a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}